{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0bcc9fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c6a839",
   "metadata": {},
   "source": [
    "### Seed fixation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b419e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value = 42\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "058e06f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accelerometer1RMS</th>\n",
       "      <th>Accelerometer2RMS</th>\n",
       "      <th>Current</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Thermocouple</th>\n",
       "      <th>Voltage</th>\n",
       "      <th>Volume Flow RateRMS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-03-09 10:14:33</th>\n",
       "      <td>0.026588</td>\n",
       "      <td>0.040111</td>\n",
       "      <td>1.33020</td>\n",
       "      <td>0.054711</td>\n",
       "      <td>79.3366</td>\n",
       "      <td>26.0199</td>\n",
       "      <td>233.062</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-09 10:14:34</th>\n",
       "      <td>0.026170</td>\n",
       "      <td>0.040453</td>\n",
       "      <td>1.35399</td>\n",
       "      <td>0.382638</td>\n",
       "      <td>79.5158</td>\n",
       "      <td>26.0258</td>\n",
       "      <td>236.040</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-09 10:14:35</th>\n",
       "      <td>0.026199</td>\n",
       "      <td>0.039419</td>\n",
       "      <td>1.54006</td>\n",
       "      <td>0.710565</td>\n",
       "      <td>79.3756</td>\n",
       "      <td>26.0265</td>\n",
       "      <td>251.380</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-09 10:14:36</th>\n",
       "      <td>0.026027</td>\n",
       "      <td>0.039641</td>\n",
       "      <td>1.33458</td>\n",
       "      <td>0.382638</td>\n",
       "      <td>79.6097</td>\n",
       "      <td>26.0393</td>\n",
       "      <td>234.392</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-09 10:14:37</th>\n",
       "      <td>0.026290</td>\n",
       "      <td>0.040273</td>\n",
       "      <td>1.07851</td>\n",
       "      <td>-0.273216</td>\n",
       "      <td>79.6109</td>\n",
       "      <td>26.0420</td>\n",
       "      <td>225.342</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Accelerometer1RMS  Accelerometer2RMS  Current  Pressure  \\\n",
       "datetime                                                                       \n",
       "2020-03-09 10:14:33           0.026588           0.040111  1.33020  0.054711   \n",
       "2020-03-09 10:14:34           0.026170           0.040453  1.35399  0.382638   \n",
       "2020-03-09 10:14:35           0.026199           0.039419  1.54006  0.710565   \n",
       "2020-03-09 10:14:36           0.026027           0.039641  1.33458  0.382638   \n",
       "2020-03-09 10:14:37           0.026290           0.040273  1.07851 -0.273216   \n",
       "\n",
       "                     Temperature  Thermocouple  Voltage  Volume Flow RateRMS  \n",
       "datetime                                                                      \n",
       "2020-03-09 10:14:33      79.3366       26.0199  233.062                 32.0  \n",
       "2020-03-09 10:14:34      79.5158       26.0258  236.040                 32.0  \n",
       "2020-03-09 10:14:35      79.3756       26.0265  251.380                 32.0  \n",
       "2020-03-09 10:14:36      79.6097       26.0393  234.392                 32.0  \n",
       "2020-03-09 10:14:37      79.6109       26.0420  225.342                 32.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/valve1/0.csv\", sep=\";\", parse_dates=True, index_col=\"datetime\")\n",
    "df = df.drop([\"anomaly\", \"changepoint\"], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69dc557",
   "metadata": {},
   "source": [
    "### Make model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06be0ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(df, win_size, gap_time, step_max):\n",
    "\n",
    "    data = np.array(df, dtype=np.float64)\n",
    "    sensor_n = data.shape[1]\n",
    "    data_all = []\n",
    "    scale_n = len(win_size)\n",
    "    # min-max normalization\n",
    "    data = MinMaxScaler().fit_transform(data).T\n",
    "\n",
    "    for win in win_size:\n",
    "        matrix_all = []\n",
    "        print(f\"generating signature with window {win} ...\")\n",
    "        for t in range(win_size[-1], len(df), gap_time):\n",
    "            matrix_t = np.zeros((sensor_n, sensor_n))\n",
    "            for i in range(sensor_n):\n",
    "                for j in range(i, sensor_n):\n",
    "                    matrix_t[i][j] = np.inner(data[i, t - win:t], data[j, t - win:t])/(win) # rescale by win\n",
    "                    matrix_t[j][i] = matrix_t[i][j]\n",
    "            matrix_all.append(matrix_t)\n",
    "        data_all.append(matrix_all)\n",
    "\n",
    "    data_all = np.transpose(data_all, (1,2,3,0))\n",
    "\n",
    "    print (f\"create dataset ...\")\n",
    "\n",
    "    dataset = data_all[:step_max]\n",
    "    for i in range(step_max+1, len(data_all)+1):\n",
    "        dataset = np.append(dataset, data_all[i-step_max:i], axis=0)\n",
    "\n",
    "    return dataset.reshape([-1, step_max, sensor_n, sensor_n, scale_n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "819af676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating signature with window 5 ...\n",
      "generating signature with window 10 ...\n",
      "generating signature with window 30 ...\n",
      "create dataset ...\n"
     ]
    }
   ],
   "source": [
    "win_sizes = [5, 10, 30]\n",
    "gap_time = 1\n",
    "h = 5\n",
    "\n",
    "train_size = 400\n",
    "\n",
    "dataset = create_dataset(df[:train_size], win_sizes, gap_time, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d06a2c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0485b642",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, TimeDistributed, Conv2D, ConvLSTM2D, Conv2DTranspose, RepeatVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b9d63e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSCRED:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, train_dataset, batch_size=32, epochs=2):\n",
    "        \n",
    "        t, h, n, _, s = train_dataset.shape\n",
    "        input_layer = Input(shape = (h, n, n, s))\n",
    "        \n",
    "        encoder_conv1 = TimeDistributed(Conv2D(filters = 32, kernel_size = 3, \n",
    "                               strides = 1, padding = \"same\",\n",
    "                               activation=\"selu\", kernel_initializer = \"glorot_uniform\"))(input_layer)\n",
    "        \n",
    "        encoder_conv2 = TimeDistributed(Conv2D(filters = 64, kernel_size = 3, \n",
    "                               strides = 2, padding = \"same\",\n",
    "                               activation=\"selu\", kernel_initializer = \"glorot_uniform\"))(encoder_conv1)\n",
    "        \n",
    "        encoder_conv3 = TimeDistributed(Conv2D(filters = 128, kernel_size = 2, \n",
    "                               strides = 2, padding = \"same\",\n",
    "                               activation=\"selu\", kernel_initializer = \"glorot_uniform\"))(encoder_conv2)\n",
    "        \n",
    "        encoder_conv4 = TimeDistributed(Conv2D(filters = 256, kernel_size = 2, \n",
    "                               strides = 2, padding = \"same\",\n",
    "                               activation=\"selu\", kernel_initializer = \"glorot_uniform\"))(encoder_conv3)\n",
    "        \n",
    "        print(encoder_conv4.shape)\n",
    "        \n",
    "        \n",
    "        lstm_conv1 =  ConvLSTM2D(filters=32, kernel_size = 2, \n",
    "                                 padding = \"same\", return_sequences = False)(encoder_conv1)\n",
    "        \n",
    "        lstm_conv2 =  ConvLSTM2D(filters=64, kernel_size = 2, \n",
    "                                 padding = \"same\", return_sequences = False)(encoder_conv2)\n",
    "        \n",
    "        lstm_conv3 =  ConvLSTM2D(filters=128, kernel_size = 2, \n",
    "                                 padding = \"same\", return_sequences = False)(encoder_conv3)\n",
    "        \n",
    "        lstm_conv4 =  ConvLSTM2D(filters=256, kernel_size = 2, \n",
    "                                 padding = \"same\", return_sequences = False)(encoder_conv4)\n",
    "\n",
    "        \n",
    "        decoder_conv4 = Conv2DTranspose(filters=128, kernel_size = 2, strides = 2,\n",
    "                                       kernel_initializer = \"glorot_uniform\", padding = \"same\",\n",
    "                                       activation = \"selu\")(lstm_conv4)\n",
    "        decoder4_out = tf.concat([decoder_conv4, lstm_conv3], axis = 3)\n",
    "        \n",
    "        decoder_conv3 = Conv2DTranspose(filters=64, kernel_size = 2, strides = 2,\n",
    "                                       kernel_initializer = \"glorot_uniform\", padding = \"same\",\n",
    "                                       activation = \"selu\")(decoder4_out)\n",
    "        decoder3_out = tf.concat([decoder_conv3, lstm_conv2], axis = 3)\n",
    "        \n",
    "        decoder_conv2 = Conv2DTranspose(filters=32, kernel_size = 3, strides = 2,\n",
    "                                       kernel_initializer = \"glorot_uniform\", padding = \"same\",\n",
    "                                       activation = \"selu\")(decoder3_out)\n",
    "        decoder2_out = tf.concat([decoder_conv2, lstm_conv1], axis = 3)\n",
    "        \n",
    "        decoder_conv1 = Conv2DTranspose(filters=s, kernel_size = 3, strides = 1,\n",
    "                                       kernel_initializer = \"glorot_uniform\", padding = \"same\",\n",
    "                                       activation = \"selu\")(decoder2_out)\n",
    "        \n",
    "        def loss_function(y_true, y_pred):\n",
    "            return tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "        \n",
    "        self.model = Model(input_layer, decoder_conv1)\n",
    "        self.model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001), \n",
    "                           loss=loss_function)\n",
    "        \n",
    "        self.model.fit(train_dataset, train_dataset, epochs=epochs, batch_size=batch_size, verbose=True)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, test_dataset):\n",
    "        self.model.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c81c0914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 5, 1, 1, 256)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"repeat_vector_2\" is incompatible with the layer: expected ndim=2, found ndim=4. Full shape received: (None, 8, 8, 32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [57]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mMSCRED\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [56]\u001b[0m, in \u001b[0;36mMSCRED.fit\u001b[0;34m(self, train_dataset, batch_size, epochs)\u001b[0m\n\u001b[1;32m     35\u001b[0m lstm_conv3 \u001b[38;5;241m=\u001b[39m  ConvLSTM2D(filters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, kernel_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, \n\u001b[1;32m     36\u001b[0m                          padding \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m\"\u001b[39m, return_sequences \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)(encoder_conv3)\n\u001b[1;32m     38\u001b[0m lstm_conv4 \u001b[38;5;241m=\u001b[39m  ConvLSTM2D(filters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m, kernel_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, \n\u001b[1;32m     39\u001b[0m                          padding \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m\"\u001b[39m, return_sequences \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)(encoder_conv4)\n\u001b[0;32m---> 41\u001b[0m lstm_conv1 \u001b[38;5;241m=\u001b[39m \u001b[43mRepeatVector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlstm_conv1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m lstm_conv2 \u001b[38;5;241m=\u001b[39m RepeatVector(h)(lstm_conv2)\n\u001b[1;32m     43\u001b[0m lstm_conv3 \u001b[38;5;241m=\u001b[39m RepeatVector(h)(lstm_conv3)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/input_spec.py:213\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    211\u001b[0m   ndim \u001b[38;5;241m=\u001b[39m shape\u001b[38;5;241m.\u001b[39mrank\n\u001b[1;32m    212\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m ndim \u001b[38;5;241m!=\u001b[39m spec\u001b[38;5;241m.\u001b[39mndim:\n\u001b[0;32m--> 213\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    214\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis incompatible with the layer: \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    215\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpected ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, found ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    216\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFull shape received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(shape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mmax_ndim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    218\u001b[0m   ndim \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mrank\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"repeat_vector_2\" is incompatible with the layer: expected ndim=2, found ndim=4. Full shape received: (None, 8, 8, 32)"
     ]
    }
   ],
   "source": [
    "model = MSCRED().fit(dataset, epochs=10, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fb300737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating signature with window 5 ...\n",
      "generating signature with window 10 ...\n",
      "generating signature with window 30 ...\n",
      "create dataset ...\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(create_dataset(df, win_sizes, gap_time, h))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
