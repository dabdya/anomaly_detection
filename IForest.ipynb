{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f844462d",
   "metadata": {},
   "source": [
    "### Isolation Forest\n",
    "\n",
    "Данный подход не требует нормальности данных (в смысле рабочего состояния системы), т.е. в данных могут быть аномалии. **Из-за своей склонности к изоляции аномалии изолируются ближе к корню дерева.** В то время как нормальные состояния системы находится как можно глубже. При моделировании строится ансамбль деревьев для предлагаемого датасета, тогда аномалии - это те экземпляры, которые имеют короткую среднюю длину пути. Существует два гиперпараметра модели: количество деревьев в лесу и размер подвыборки.\n",
    "\n",
    "Изолировать - это значит отделить один объект от остальных. Аномалии наиболее предрасположены к изоляции, поскольку их мало и они отличаются от нормальных объектов. В случайном дереве разбиение экземпляров рекурсивно повторяется до тех пор, пока все экземпляры не будут изолированы. Если лес случайных деревьев вместе создает более короткие пути для некоторых конкретных точек, то они, скорее всего, будут аномалиями. \n",
    "\n",
    "Нормальный объект требует больших разбиений для того чтобы быть изолированным, в то время как аномальный объект будет отделен на более ранней стадии. **При разбиении рандомно выбирается признак и сплит-значение** между минимальным и максимальным значениями признака.\n",
    "\n",
    "Поскольку рекурсивное разбиение может быть представлено в деревовидной структуре, то количество разбиений соответсвует длине пути из корня в терминальную вершину. Поскольку каждое разбиение рандомно, то в отдельности деревья сгенерируют различные разбиения. Тогда для каждой вершины посмотрим его высоту в дереве и усредним по рамеру леса. При увеличении количества деревьев средняя высота будет сходиться к конкретному числу.\n",
    "\n",
    "<img src=\"iforest.png\" alt=\"Drawing\" style=\"width: 400px; height: 600px\"/>\n",
    "\n",
    "На картинках видно, что аномалия довольно быстро отсекается, и чем больше деревьев в ансамбле тем конкретнее длина пути\n",
    "\n",
    "**Определение Isolation Tree**. Пусть $T$ это произвольная вершина. Тогда $T$ это либо внешняя вершина без детей, либо внутрення с двумя детьми $(T_l, T_r)$ и *тестом*. Тест содержит значения признака $q$ и сплит-значение $p$, и по критерию $q < p$ разделяет данные в $T_l$ и $T_r$ соответственно.\n",
    "\n",
    "Пусть дана выборка $X = \\{x_1, x_2, \\ldots, x_n\\}$, тогда для построения модели будем рекурсивно разделять выборку по рандомному признаку $q$ и сплит-значению $p$ до тех пор пока:\n",
    "* не будет достигнут лимит по высоте дерева (как гиперпараметр модели)\n",
    "* размер выборки не будет равняться единице $|X| = 1$\n",
    "* все объекты в выборке не будут иметь одинаковые значения\n",
    "\n",
    "Isolation Tree это бинарное дерево, т.е. каждая вершина имеет не больше двух дочерних вершин. Чтобы обнаружить аномалии нужно отсортировать вершины по длине пути или *anomaly score* в порядке возрастания, тогда вверху списка будут аномальные вершины.\n",
    "\n",
    "**Длина пути и anomaly score**. Длина пути $h(x)$ это просто количество ребер от корня дерева до вершины $x$.\n",
    "\n",
    "Поскольку $ITree$ имеет аналогичную структуру, что и $BST$ (двоичное дерево поиска), то средняя длина внешнего пути оценивается как [неудачный поиск в BST](https://book.huihoo.com/data-structures-and-algorithms-with-object-oriented-design-patterns-in-java/html/page308.html), а здесь [более подробно про связь с гармоническими числами](https://www.cs.csustan.edu/~john/classes/previous_semesters/cs3100_datastructures/2000_04_Fall/Examples/Trees/averageSearchInBST.html). Откуда можно получить среднюю глубину внешней вершины\n",
    "$$\\large c(n) = 2H(n-1) - \\frac{2(n-1)}{n}$$\n",
    "\n",
    "Поскольку $c(n)$ это среднее значение, то можно использовать его для нормализации $h(x)$. Таким образом *anomaly score* для объекта $x$ определяется как $$\\Large s(x, n) = 2^{-\\frac{E(h(x))}{c(n)}}$$\n",
    "\n",
    "где $E(h(x))$ это средняя длина пути для объекта $x$ на основе всех деревьев\n",
    "\n",
    "<img src=\"anomaly_score.png\" alt=\"Drawing\" style=\"width: 400px; height: 300px\"/>\n",
    "\n",
    "Из графика видно, чем чем больше $E(h(x))$ относительно $c(n)$ тем ближе *anomaly score* к нулю и тем менее вероятно что объект $x$ является аномалией. И наоборот. Поэтому можно сделать несколько важных выводов:\n",
    "\n",
    "* если значение близко к единице, то это определенно аномалия\n",
    "* если объекты имеют значение $< 0.5$, то их можно рассматривать как нормальные\n",
    "\n",
    "Как ансамбль деревьев, в котором используются изолированные деревья, IForest а) идентифицирует аномалии как точки с более короткой длиной пути и б) имеет несколько деревьев, действующих как «эксперты» для выявления различных аномалий. Поскольку IForest не нужно изолировать все нормальные экземпляры — большую часть обучающей выборки IForest может хорошо работать с частичной моделью, не изолируя все нормальные точки, и строит модели, используя небольшой размер выборки. При этом большой размер выборки снижает способность IForest изолировать аномалии, поскольку обычные экземпляры могут мешать процессу изоляции и, следовательно, уменьшают его способность однозначно изолировать аномалии. \n",
    "\n",
    "**Основые проблемы при поиске аномалий**: *swamping* и *masking*. \n",
    "\n",
    "*Swamping* относится к ошибочной идентификации нормальных экземпляров как аномалий (оно же ложноположительное обнаружение). Когда нормальные экземпляры находятся слишком близко к аномалиям, количество разделов, необходимых для разделения аномалий, увеличивается, что затрудняет отличить аномалии от нормальных экземпляров. \n",
    "\n",
    "*Masking* это наличие слишком большого количества аномалий (групповые аномалии), скрывающих свое присутствие. Когда кластер аномалий большой и плотный, также увеличивается количество разделов для изоляции каждой аномалии. \n",
    "\n",
    "В этих обстоятельствах оценки с использованием $Itrees$ имеют большую длину пути, что и затрудняет обнаружение аномалий. Обе проблемы вытекают из слишком большого размера выборки. Способность $IForest$ работать с частичной моделью позволяет избежать этих проблем, и этим нужно пользоваться. Это связано с тем, что: 1) подвыборка контролирует размер данных, что помогает IForest лучше изолировать аномалии и 2) каждое изолированное дерево может быть специализировано, поскольку каждая подвыборка включает различный набор аномалий или даже не содержит аномалий. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2d6131",
   "metadata": {},
   "source": [
    "###  Обнаружение аномалий с помощью IForest\n",
    "\n",
    "Алгоритм состоит из двух стадий, как в классическом машинном обучении. Первая стадия - тренировка, строит $ITrees$ на подвыборках из тренировочных данных. На второй стадии - тестирование, тестовые экземпляры проходят через деревья изоляции, чтобы получить оценку аномалии для каждого экземпляра."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "c886f755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "60fd9368",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mar(test, pred):\n",
    "    p = pred.values.astype(bool)\n",
    "    t = test.values.astype(bool)\n",
    "    fn = (~p & t).sum()\n",
    "    tp = (p & t).sum()\n",
    "    return fn / (tp + fn)\n",
    "\n",
    "def far(test, pred):\n",
    "    p=pred.values.astype(bool)\n",
    "    t=test.values.astype(bool)\n",
    "    fp = (p & ~t).sum()\n",
    "    tn = (~p & ~t).sum()\n",
    "    return fp / (fp + tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "36180029",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(test, pred):\n",
    "    p=pred.values.astype(bool)\n",
    "    t=test.values.astype(bool)\n",
    "    tp = (p & t).sum()\n",
    "    fp = (p & ~t).sum()\n",
    "    fn = (~p & t).sum()\n",
    "    return tp / (tp + 0.5 * (fp + fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "856df828",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "all_files = []\n",
    "for root, dirs, files in os.walk(\"data/\"):\n",
    "    for file in files:\n",
    "        f_name = f'{root}/{file}'\n",
    "        if file.endswith(\".csv\") and \"anomaly-free\" not in file and \"other/2.csv\" not in f_name:\n",
    "             all_files.append(f_name)    #other/2.csv содержит только 100 здоровых сэмплов\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "610d7718",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_df = [pd.read_csv(file, \n",
    "                          sep=';', \n",
    "                          index_col='datetime', \n",
    "                          parse_dates=True) for file in all_files][13:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "97a1128d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "560"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "health_prefix_lens=[]\n",
    "for df in list_of_df:\n",
    "    health_beginning_length = df[df.anomaly.cumsum()==0].shape[0]\n",
    "    health_prefix_lens.append(health_beginning_length)\n",
    "train_prefix_len = min(health_prefix_lens)\n",
    "train_prefix_len # число сэмплов для обучения в начале каждого ряда"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "dd587281",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/valve1/3.csv\", sep=';', index_col='datetime', parse_dates=True)\n",
    "df = df[health_beginning_length:]\n",
    "y_test = df[\"anomaly\"]\n",
    "df.drop([\"anomaly\", \"changepoint\"], inplace=True, axis=1)\n",
    "df.sort_index(inplace=True)\n",
    "x_test = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "431376db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inner-appendix",
   "metadata": {},
   "source": [
    "# Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "c3b84d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbb8cb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [00:05,  3.43it/s]"
     ]
    }
   ],
   "source": [
    "clf = IsolationForest(contamination=0.01, n_jobs=-1)\n",
    "list_of_predictions=[]\n",
    "for i, df in tqdm(enumerate(list_of_df)):\n",
    "    df = df.drop([\"anomaly\", \"changepoint\"], axis=1)\n",
    "    x = df.values\n",
    "    clf.fit(x[:train_prefix_len])\n",
    "    predictions_raw = clf.predict(x_test.values)\n",
    "    predictions = pd.Series(predictions_raw).map({-1: 1, 1:0})\n",
    "    list_of_predictions.append(predictions)\n",
    "all_predictions = pd.DataFrame(list_of_predictions).T\n",
    "voting_res = (all_predictions.mean(axis=1)>0.5).astype(int)\n",
    "f1_score(y_test, voting_res), mar(y_test, voting_res), far(y_test, voting_res), all_predictions.sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selected-values",
   "metadata": {},
   "source": [
    "## Results Interpretation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1158919e",
   "metadata": {},
   "outputs": [],
   "source": [
    "health = clf.decision_function(x)\n",
    "df_health = df.copy()\n",
    "df_health[\"Health\"] = health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e60cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_health.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f834681",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(health)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b09df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "ax.set_title(\"Health\")\n",
    "ax.plot(df_health[\"Health\"].resample(\"15S\").mean())\n",
    "ax.axhspan(-0.02, 0.02, alpha=0.2, color=\"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f997d66b",
   "metadata": {},
   "source": [
    "$$\\large MAR = \\frac{FN}{TP + FN}$$\n",
    "\n",
    "$$\\large FAR = \\frac{FP}{FP + TN}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9810e396",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.astype(int)\n",
    "# 1 аномалия есть. Positive ~ is anomaly\n",
    "# 0 аномалии нет. Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd752e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mar_res = mar(y_test, voting_res) # пропущенные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b42d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "far_res = far(y_test, voting_res) # ложноопределенные"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622ec088",
   "metadata": {},
   "source": [
    "$$\\large F1 = \\frac{TP}{TP + 0.5(FP + FN)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2059525f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_res = f1_score(y_test, voting_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ab66d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.subplot(2, 1, 1)\n",
    "fig, axs = plt.subplots(2, 1, figsize=(20,10))\n",
    "temperatures = df.Temperature\n",
    "axs[0].plot(temperatures)\n",
    "\n",
    "y = pd.Series(voting_res)\n",
    "anomalies_indecies = y.index[y == 1]\n",
    "axs[0].scatter(df.index[anomalies_indecies], temperatures[anomalies_indecies], color='r')\n",
    "# #axs.scatter(cpi, temperatures[cpi], color='g', marker='^', s=300)\n",
    "axs[0].set_title(\"Temperature Predicted\")\n",
    "\n",
    "axs[1].plot(temperatures)\n",
    "y = pd.Series(y_test)\n",
    "anomalies_indecies = pd.Series(y.values).index[y == 1]\n",
    "axs[1].scatter(df.index[anomalies_indecies], temperatures[anomalies_indecies], color='r')\n",
    "# #axs.scatter(cpi, temperatures[cpi], color='g', marker='^', s=300)\n",
    "axs[1].set_title(\"Temperature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wired-criterion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.subplot(2, 1, 1)\n",
    "fig, axs = plt.subplots(2, 1, figsize=(20,10))\n",
    "temperatures = df.Temperature\n",
    "# axs[0].plot(temperatures)\n",
    "\n",
    "y = pd.Series(predictions)\n",
    "axs[0].plot(range(len(y)), y, marker='o')\n",
    "axs[0].plot(range(len(y_test)), y_test)\n",
    "# axs[0].scatter(df.index[anomalies_indecies], temperatures[anomalies_indecies], color='r')\n",
    "# #axs.scatter(cpi, temperatures[cpi], color='g', marker='^', s=300)\n",
    "# axs[0].set_title(\"Temperature Predicted\")\n",
    "\n",
    "y = pd.Series(predictions)\n",
    "axs[1].plot(range(len(y[:400])), y[:400], marker='o')\n",
    "axs[1].plot(range(len(y_test[:400])), y_test[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5681c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_res, far_res, mar_res "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "difficult-slovak",
   "metadata": {},
   "source": [
    "## Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viral-spectacular",
   "metadata": {},
   "source": [
    "Если в выборке большая доля аномалий, лучше обучаться только на здоровых данных.\n",
    "Обучили несколько IForest'ов на разных DF. Спрогнозировали на одном и провели голосование."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f4c9d7",
   "metadata": {},
   "source": [
    "Алгоритм  |  F1  | FAR | MAR | \n",
    "--- | --- | --- |--- |\n",
    "Perfect | 1 | 0 | 0\n",
    "SKAB IForest | 0.4 | 0.06 | 0.72\n",
    "IForest | 0.75 | 0.18 | 0.31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d818a057",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
