{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e92a05e-9fcf-44b6-ab4f-dcbbd646d513",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from utils.data import create_sequences\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from utils.metrics import mar, far, f1_score\n",
    "\n",
    "from models.lstm_ae import LSTM_AE\n",
    "from utils.data import load_df, load_df_with_names, load_df_by_names\n",
    "from utils.metrics import f1_score, far, mar\n",
    "\n",
    "from typing import Dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bc2f287-ae41-4721-b064-45f7d4d03da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value = 42\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "208aa9ca-213c-4f89-8cff-dd0fa08ed304",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Accelerometer1RMS', 'Accelerometer2RMS', 'Current', 'Pressure',\n",
    "       'Temperature', 'Thermocouple', 'Voltage', 'Volume Flow RateRMS']\n",
    "# redundant_features = ['anomaly','changepoint','Accelerometer1RMS', 'Accelerometer2RMS', 'Current','Voltage','Pressure','Temperature', 'Thermocouple' ]\n",
    "redundant_features = ['anomaly','changepoint','Accelerometer1RMS', 'Accelerometer2RMS', 'Current','Voltage','Thermocouple' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ec39a0e-655e-4d25-958e-109103e10e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "518"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"./data/valve1/6.csv\", sep=\";\", parse_dates=True, index_col=\"datetime\")\n",
    "df_train.sort_index(inplace=True)\n",
    "\n",
    "first_anomaly_idx = df_train.index.get_loc(df_train[df_train[\"anomaly\"] == 1].index[0])\n",
    "df_train = df_train.drop(redundant_features, axis=1)\n",
    "train_size = int(first_anomaly_idx * 0.9)\n",
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4565e51a-77d0-4198-87e6-20ac4106f546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pressure</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Volume Flow RateRMS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-03-09 12:14:36</th>\n",
       "      <td>0.382638</td>\n",
       "      <td>71.2129</td>\n",
       "      <td>32.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-09 12:14:37</th>\n",
       "      <td>0.710565</td>\n",
       "      <td>71.4284</td>\n",
       "      <td>32.0104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-09 12:14:38</th>\n",
       "      <td>0.054711</td>\n",
       "      <td>71.3468</td>\n",
       "      <td>32.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Pressure  Temperature  Volume Flow RateRMS\n",
       "datetime                                                       \n",
       "2020-03-09 12:14:36  0.382638      71.2129              32.0000\n",
       "2020-03-09 12:14:37  0.710565      71.4284              32.0104\n",
       "2020-03-09 12:14:38  0.054711      71.3468              32.0000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = df_train[:train_size]\n",
    "x_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "221daba3-d6bf-4bed-9360-df452ada408f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.pipeline import Pipeline, Predictor\n",
    "from tensorflow import keras\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "class Config:\n",
    "    TIME_STEPS = 50\n",
    "    epochs = 1\n",
    "    batch_size = 10 \n",
    "    Q = 0.99\n",
    "    \n",
    "conf = Config\n",
    "\n",
    "class LSTM_AE_2ndPredictor:\n",
    "    def fit(self, df_train):\n",
    "        ss = StandardScaler()\n",
    "        self.ss = ss\n",
    "        x_train = df_train[:train_size]\n",
    "        x_train = np.array(ss.fit_transform(x_train))\n",
    "        x_train = create_sequences(x_train, conf.TIME_STEPS)\n",
    "\n",
    "        self.model = LSTM_AE(optimizer=optimizer, loss='mae')\n",
    "        self.model.fit(x_train, conf.epochs, conf.batch_size, conf.TIME_STEPS)\n",
    "        # health_r = pd.Series(np.sum(np.mean(np.abs(model.predict(x_train) - x_train), axis=1), axis=1))  \n",
    "        \n",
    "    def predict(self, dfs_test: Dict[str, pd.DataFrame]) -> Dict[str, pd.Series]:\n",
    "        predictions = {}\n",
    "        for file_name, df in dfs_test.items():\n",
    "            y_test = df.anomaly\n",
    "            df = df.drop(redundant_features, axis=1)\n",
    "            x_test = np.array(self.ss.transform(df))\n",
    "            x_test = create_sequences(x_test, conf.TIME_STEPS)\n",
    "            r = pd.Series(np.sum(np.mean(np.abs(self.model.predict(x_test) - x_test), axis=1), axis=1)) \n",
    "            \n",
    "            r_ratio = r/r.max()\n",
    "            smoothed = r_ratio.rolling(window = 10).mean().fillna(r_ratio.iloc[0])\n",
    "            a = smoothed.diff(10).abs()\n",
    "            IQR = a.quantile(0.75) - a.quantile(0.75)\n",
    "            UCL = a.quantile(0.75) + 1.5 * IQR\n",
    "            s = a > UCL\n",
    "            w = 10\n",
    "            is_anomaly = s.rolling(window = w).mean().fillna(s.iloc[0])\n",
    "            anomalous_data_indices = pd.Series(is_anomaly.index[is_anomaly > 0]) #+ conf.TIME_STEPS - 1\n",
    "\n",
    "            prediction = pd.Series(data=0, index=df.index)\n",
    "            prediction.iloc[anomalous_data_indices] = 1\n",
    "            predictions[file_name] = prediction\n",
    "            \n",
    "        return predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdf00300-3fc2-4684-adad-1bf989c0b4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 12s 148ms/step - loss: 0.8241\n"
     ]
    }
   ],
   "source": [
    "predictor = LSTM_AE_2ndPredictor()\n",
    "predictor.fit(df_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dce19a52-4119-4bb1-a02c-142a970bb849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(df_by_names.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6cc7ca6-1b65-4db6-9e05-80d092f4f6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_df_by_names(\"./data/\", [\"valve1\", \"valve2\"]).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "972e23f0-f036-4961-84cd-84652818f070",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_names = load_df_by_names(\"./data/\", [\"valve1\", \"valve2\"])\n",
    "y_test_by_names = {name: df.anomaly for name, df in df_by_names.items()}\n",
    "predictions_by_names = predictor.predict(df_by_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "544037db-ef3b-41fc-9dee-4349c2fc5a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics= {}\n",
    "predictions = []\n",
    "\n",
    "draw = 0\n",
    "\n",
    "for file_name, prediction in predictions_by_names.items():\n",
    "    y_test = y_test_by_names[file_name]\n",
    "    f1 = f1_score(y_test, prediction)\n",
    "    far_score = far(y_test, prediction)\n",
    "    mar_score = mar(y_test, prediction)\n",
    "    metrics[file_name[7:]] = (f1, far_score, mar_score)\n",
    "    \n",
    "    if draw:\n",
    "        title = file_name + \" f1 = {:3.2f} far = {:3.2f} mar = {:3.2f}\".format(f1, far_score, mar_score)\n",
    "        plt.title(title)\n",
    "        plt.plot(y_test)    \n",
    "        plt.plot(prediction)\n",
    "        plt.legend([\"y_test\", \"predicted\"])\n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7f12a7-e784-43de-abb7-52b876d59eaa",
   "metadata": {},
   "source": [
    "Промежуточный вывод: Наблюдается резкий рост ошибки восстановления автоэнкодером, обученном на Volume flow, Pressure, Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51e56af7-7ffd-4fd4-8b13-dbbc364a1ebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "metric | valve1\\0.csv | valve1\\1.csv | valve1\\10.csv | valve1\\11.csv | valve1\\12.csv | valve1\\13.csv | valve1\\14.csv | valve1\\15.csv | valve1\\2.csv | valve1\\3.csv | valve1\\4.csv | valve1\\5.csv | valve1\\6.csv | valve1\\7.csv | valve1\\8.csv | valve1\\9.csv | valve2\\0.csv | valve2\\1.csv | valve2\\2.csv | valve2\\3.csv\n",
       "--- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---\n",
       "F1 |0.08 | 0.51 | 0.74 | 0.89 | 0.96 | 0.93 | 0.89 | 0.89 | 0.35 | 0.46 | 0.17 | 0.86 | 0.5 | 0.88 | 0.43 | 0.91 | 0.66 | 0.89 | 0.45 | 0.87\n",
       "FAR |0.61 | 0.22 | 0.11 | 0.0 | 0.02 | 0.0 | 0.0 | 0.0 | 0.36 | 0.31 | 0.43 | 0.0 | 0.29 | 0.0 | 0.38 | 0.0 | 0.23 | 0.0 | 0.25 | 0.0\n",
       "MAR |0.92 | 0.52 | 0.29 | 0.19 | 0.05 | 0.14 | 0.2 | 0.19 | 0.62 | 0.53 | 0.83 | 0.24 | 0.49 | 0.21 | 0.53 | 0.16 | 0.3 | 0.19 | 0.57 | 0.23"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils.data import show_score_table\n",
    "\n",
    "show_score_table(metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
